{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../pyfos/')\n",
    "from pyfos.models.feedforward import build_feedforward\n",
    "from pyfos.generic.optimizer import gd_optimizer\n",
    "from pyfos.generic.regularizers import gaus_prior\n",
    "from functools import partial \n",
    "from pyfos.tc.simple import  simple_tc\n",
    "from pyfos.tc.cv import  cv_tc\n",
    "from pyfos.hyperoptimizers.drmad_optimize import drmad_optimize\n",
    "import theano\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix = np.load('../../../data/matrix.npy')\n",
    "X, Y = np.load('../../../data/linearx.npy'), np.load('../../../data/lineary.npy')\n",
    "X_train = X[:100]\n",
    "Y_train = Y[:100]\n",
    "X_test = X[100:]\n",
    "Y_test = Y[100:]\n",
    "lr = theano.shared(10**(-3))\n",
    "alphas = theano.shared(np.array([1.0, 1.0]))\n",
    "\n",
    "optimizer = partial(gd_optimizer, learning_rate=lr)\n",
    "model_build = partial(build_feedforward, structure = [2,1], nonlinearity=lambda x:x, log_alphas=alphas, bias=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.36978613  0.25916244]\n"
     ]
    }
   ],
   "source": [
    "def choicer():\n",
    "    a1 = np.random.uniform(low=-6.0, high=6.0)\n",
    "    a2 = np.random.uniform(low=-6.0, high=6.0)\n",
    "    a1 = np.sqrt(10**(a1))\n",
    "    a2 = np.sqrt(10**(a2))\n",
    "    return np.log([a1,a2])\n",
    "print choicer()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calbirate: alpha\n",
      "[array([-1., -1.]), 0.01]\n",
      "1.0 31.5182199283\n",
      "1.0 31.5182199283\n",
      "1.0 31.5182199283\n",
      "1.0 31.5182199283\n",
      "1.0 31.5182199283\n",
      "1.0 31.5182199283\n",
      "1.0 31.5182199283\n",
      "1.0 31.5182199283\n",
      "1.0 31.5182199283\n",
      "1.0 31.5182199283\n",
      "[array([ 10.36163292,  10.36163292]), 0.01]\n",
      "10.3616329185 7.72659486152e-13\n",
      "10.3616329185 7.72659486152e-13\n",
      "10.3616329185 7.72659486152e-13\n",
      "10.3616329185 7.72659486152e-13\n",
      "10.3616329185 7.72659486152e-13\n",
      "10.3616329185 7.72659486152e-13\n",
      "10.3616329185 7.72659486152e-13\n",
      "10.3616329185 7.72659486152e-13\n",
      "10.3616329185 7.72659486152e-13\n",
      "10.3616329185 7.72659486152e-13\n",
      "final [0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "hyp_lr_range = [0.0, 0.0] \n",
    "print 'calbirate: alpha'\n",
    "found = False\n",
    "for h in [  [np.array([-1.0, -1.0]), 10**(-2)],\n",
    "            #[np.array([np.log(np.sqrt(10**(0))), np.log(np.sqrt(10**(0)))]), 10**(-2)],\n",
    "             [np.array([np.log(np.sqrt(10**9)), np.log(np.sqrt(10**9))]), 10**(-2)]]: \n",
    "    print h\n",
    "    while True:\n",
    "\n",
    "            \n",
    "            lr.set_value(h[1])\n",
    "            alphas.set_value(h[0])\n",
    "\n",
    "\n",
    "\n",
    "            score = drmad_optimize(partial(cv_tc, k =4,  batch_size=75), model_build, optimizer, 10, 75, 10,  X_train, Y_train, \n",
    "    [alphas], lr,  lr=hyp_lr_range[0],  lr_for_learning_rate=0.0, verbose=-1, use_hessian=False).history[-1][1]\n",
    "            if lr.eval()>1.0 or np.max(abs(alphas.eval()))>12 or  np.isnan(score) or np.isinf(score):\n",
    "                print 'BAD'\n",
    "                print alphas.eval()\n",
    "                hyp_lr_range[0] = hyp_lr_range[0]/2\n",
    "            else:\n",
    "                \n",
    "                break\n",
    "            \n",
    "print 'final', hyp_lr_range            \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attemp\n",
      "[ 6.64379711 -6.4309027 ] 0.01\n",
      "trial 0\n",
      "iteration 0, internal loss=-1282.8385734 time=0.00702095031738\n",
      "validation score:  -2.46628049632e+67\n",
      "reverse-iteration 0, gradients:[[ -2.64336428e+53  -9.50283763e+70]] time:0.000593900680542\n",
      "max abs grad 9.50283763427e+70\n",
      "6.64379711116 5.22656069885e+71\n",
      "new hyperparam values: [array([ -1.45385035e+55,  -5.22656070e+72])]\n",
      "max abs 5.22656069885e+72\n",
      "trial 1\n",
      "iteration 0, internal loss=nan time=0.00107789039612\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000653982162476\n",
      "max abs grad nan\n",
      "5.22656069885e+72 nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 2\n",
      "iteration 0, internal loss=nan time=0.00299501419067\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000706911087036\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 3\n",
      "iteration 0, internal loss=nan time=0.0033221244812\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000632047653198\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 4\n",
      "iteration 0, internal loss=nan time=0.00282096862793\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.00082802772522\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 5\n",
      "iteration 0, internal loss=nan time=0.00701117515564\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.0015230178833\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 6\n",
      "iteration 0, internal loss=nan time=0.00692009925842\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.00192499160767\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 7\n",
      "iteration 0, internal loss=nan time=0.0038149356842\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.00352311134338\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 8\n",
      "iteration 0, internal loss=nan time=0.00874018669128\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000617980957031\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 9\n",
      "iteration 0, internal loss=nan time=0.00465106964111\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.00060510635376\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 10\n",
      "iteration 0, internal loss=nan time=0.00551915168762\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000623941421509\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 11\n",
      "iteration 0, internal loss=nan time=0.00469398498535\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000604152679443\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 12\n",
      "iteration 0, internal loss=nan time=0.00656986236572\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000617027282715\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 13\n",
      "iteration 0, internal loss=nan time=0.00385904312134\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000637054443359\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 14\n",
      "iteration 0, internal loss=nan time=0.00323081016541\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000625848770142\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 15\n",
      "iteration 0, internal loss=nan time=0.0031521320343\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000636100769043\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 16\n",
      "iteration 0, internal loss=nan time=0.00361394882202\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000617980957031\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 17\n",
      "iteration 0, internal loss=nan time=0.00711512565613\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000689029693604\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 18\n",
      "iteration 0, internal loss=nan time=0.00375413894653\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000638008117676\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 19\n",
      "iteration 0, internal loss=nan time=0.0039370059967\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000613212585449\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 20\n",
      "iteration 0, internal loss=nan time=0.00289297103882\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000641107559204\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 21\n",
      "iteration 0, internal loss=nan time=0.00207209587097\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000607013702393\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 22\n",
      "iteration 0, internal loss=nan time=0.0064001083374\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000614881515503\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 23\n",
      "iteration 0, internal loss=nan time=0.00411605834961\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000617027282715\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 24\n",
      "iteration 0, internal loss=nan time=0.0037260055542\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000617980957031\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 25\n",
      "iteration 0, internal loss=nan time=0.00243592262268\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000649929046631\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 26\n",
      "iteration 0, internal loss=nan time=0.00275993347168\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000616073608398\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 27\n",
      "iteration 0, internal loss=nan time=0.00235986709595\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000663995742798\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 28\n",
      "iteration 0, internal loss=nan time=0.00396108627319\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000661849975586\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 29\n",
      "iteration 0, internal loss=nan time=0.00233292579651\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000611066818237\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 30\n",
      "iteration 0, internal loss=nan time=0.00319004058838\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000640869140625\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 31\n",
      "iteration 0, internal loss=nan time=0.00323891639709\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000616073608398\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 32\n",
      "iteration 0, internal loss=nan time=0.00692915916443\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000624179840088\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 33\n",
      "iteration 0, internal loss=nan time=0.00363302230835\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000663042068481\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 34\n",
      "iteration 0, internal loss=nan time=0.00367712974548\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.00064492225647\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 35\n",
      "iteration 0, internal loss=nan time=0.00339889526367\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000607013702393\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 36\n",
      "iteration 0, internal loss=nan time=0.00406980514526\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000667095184326\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 37\n",
      "iteration 0, internal loss=nan time=0.00558090209961\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000656127929688\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 38\n",
      "iteration 0, internal loss=nan time=0.00369596481323\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.00068998336792\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 39\n",
      "iteration 0, internal loss=nan time=0.00336885452271\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000629186630249\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 40\n",
      "iteration 0, internal loss=nan time=0.00355386734009\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.00063681602478\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 41\n",
      "iteration 0, internal loss=nan time=0.00351285934448\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000612020492554\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 42\n",
      "iteration 0, internal loss=nan time=0.00616693496704\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000615835189819\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 43\n",
      "iteration 0, internal loss=nan time=0.0039849281311\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.00061297416687\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 44\n",
      "iteration 0, internal loss=nan time=0.00273585319519\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.00062084197998\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 45\n",
      "iteration 0, internal loss=nan time=0.00454688072205\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000648975372314\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 46\n",
      "iteration 0, internal loss=nan time=0.00413703918457\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000619173049927\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 47\n",
      "iteration 0, internal loss=nan time=0.00639200210571\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000625133514404\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 48\n",
      "iteration 0, internal loss=nan time=0.00153112411499\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000630140304565\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "trial 49\n",
      "iteration 0, internal loss=nan time=0.00291299819946\n",
      "validation score:  nan\n",
      "reverse-iteration 0, gradients:[[ nan  nan]] time:0.000630140304565\n",
      "max abs grad nan\n",
      "nan nan\n",
      "new hyperparam values: [array([ nan,  nan])]\n",
      "max abs nan\n",
      "validation score:  nan\n",
      "final [ nan  nan] 0.01\n",
      "attemp\n",
      "[-4.53533258 -5.20120035] 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-83e82ab8cf85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     bests.append( drmad_optimize(partial(cv_tc, k =4,  batch_size=75), model_build, optimizer, 50, 75, 10,  X_train, Y_train, \n\u001b[1;32m---> 18\u001b[1;33m     [alphas], lr,  lr=10.0,  lr_for_learning_rate=0.0,use_hessian=False, verbose=100))\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'final'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/legin/svn074/Bakhteev2017Hypergrad/code/pyfos/hyperoptimizers/drmad_optimize.pyc\u001b[0m in \u001b[0;36mdrmad_optimize\u001b[1;34m(trainig_criterion, model_constructor, param_optimizer, trial_num, batch_size, train_iteration_num, X_data, Y_data, hyperparams, learning_rate_param, lr, lr_for_learning_rate, limits, lr_limits, verbose, use_hessian)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mY_data_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtime_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mtraining_procedure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainig_criterion\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmodel_constructor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_data\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_procedure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/legin/svn074/Bakhteev2017Hypergrad/code/pyfos/tc/cv.pyc\u001b[0m in \u001b[0;36mcv_tc\u001b[1;34m(model_constructor, param_optimizer, X_data, Y_data, k, validation_part, batch_size)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mvalidations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mtrain_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgivens\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mgivens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mmonitor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mgivens\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mgivens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    327\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1792\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1794\u001b[1;33m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1795\u001b[0m             defaults)\n\u001b[0;32m   1796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[0;32m   1472\u001b[0m                         optimizer, inputs, outputs)\n\u001b[0;32m   1473\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1474\u001b[1;33m                     \u001b[0moptimizer_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1476\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    233\u001b[0m                 \u001b[0mnb_nodes_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                 \u001b[0msub_prof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m                 \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    233\u001b[0m                 \u001b[0mnb_nodes_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                 \u001b[0msub_prof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m                 \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m   7287\u001b[0m                 \u001b[1;31m# Don't try to fuse node that have already been fused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7288\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7289\u001b[1;33m                     \u001b[0mnew_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7290\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mnew_outputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7291\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_outputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mlocal_fuse\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m   7234\u001b[0m         \u001b[1;31m# debug mode will be faster as it won't test all intermediate step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7235\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7236\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocal_fuse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7237\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7238\u001b[0m                 \u001b[1;31m# print n,ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mlocal_fuse\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m   7222\u001b[0m         \u001b[1;31m# create the new node.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7223\u001b[0m         \u001b[1;31m# Do not call make_node to have test_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7224\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7225\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7226\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \"\"\"\n\u001b[0;32m    614\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'return_list'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m         \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'off'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/elemwise.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mas_tensor_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         out_dtypes, out_broadcastables, inputs = self.get_output_info(\n\u001b[1;32m--> 578\u001b[1;33m             DimShuffle, *inputs)\n\u001b[0m\u001b[0;32m    579\u001b[0m         outputs = [TensorType(dtype=dtype, broadcastable=broadcastable)()\n\u001b[0;32m    580\u001b[0m                    for dtype, broadcastable in izip(out_dtypes,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/elemwise.pyc\u001b[0m in \u001b[0;36mget_output_info\u001b[1;34m(self, dim_shuffle, *inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m                                           self.scalar_op.nout)\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mget_output_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_shuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m         \"\"\"Return the outputs dtype and broadcastable pattern and the\n\u001b[0;32m    515\u001b[0m         \u001b[0mdimshuffled\u001b[0m \u001b[0mniputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bests = []\n",
    "bests = []\n",
    "for _ in xrange(10):\n",
    "    print 'attemp'\n",
    "    \n",
    "    hyp_lr_range = [0.001, 10**(-10)] \n",
    "    lr_value = 10.0**(-2)\n",
    "    alphas_value = choicer()\n",
    "    print alphas_value, lr_value\n",
    "    lr.set_value(lr_value)\n",
    "    alphas.set_value(alphas_value)\n",
    "\n",
    "    \n",
    "    lr.set_value(lr_value)\n",
    "    alphas.set_value(alphas_value)\n",
    "    \n",
    "    bests.append( drmad_optimize(partial(cv_tc, k =4,  batch_size=75), model_build, optimizer, 50, 75, 10,  X_train, Y_train, \n",
    "    [alphas], lr,  lr=10.0,  lr_for_learning_rate=0.0,use_hessian=False, verbose=100))\n",
    "    print 'final', alphas.eval(), lr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEGCAYAAAB2EqL0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8v8B6jdF4+4LkpMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2f2a875d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#bests = bests2[:]\n",
    "import cPickle\n",
    "#with open('results_cv_mad.pckl','rb') as inp:\n",
    "#    bests = cPickle.load(inp)\n",
    "for b in bests:\n",
    "    history = []\n",
    "    for i in xrange(0, len(b.history)):\n",
    "        \n",
    "        best_value = max([h[1] for h in b.history[:i+1]])\n",
    "        \n",
    "        history.append(best_value)\n",
    "    plt.plot(history)\n",
    "#plt.ylim((-100, -80))\n",
    "#plt.xlim((1,50))\n",
    "\n",
    "import cPickle\n",
    "with open('results_cv_mad.pckl','wb') as out:\n",
    "    cPickle.dump(bests, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fec000b6544b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#print b.history[best][2][m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import theano.tensor as T\n",
    "X = T.matrix()\n",
    "result = []\n",
    "models = []\n",
    "predicts = []\n",
    "\n",
    "for m in xrange(4):\n",
    "    models.append(model_build(dataset_size=100))\n",
    "    predict = models[m].predict_var(X)\n",
    "    predicts.append(theano.function([X], predict))\n",
    "for b in bests:\n",
    "    scores = [b.history[i][1] for i in xrange(len(b.history))]\n",
    "    best = np.argmax(scores)\n",
    "    \n",
    "    for m in xrange(4):\n",
    "        #print b.history[best][2][m]\n",
    "        models[m].params.set_value(b.history[best][2][m])\n",
    "        result.append(np.mean((predicts[m](X_test)[:,0]-Y_test)**2))\n",
    "        print result[-1]\n",
    "    \"\"\"\n",
    "    bests.append( random_optimize(partial(cv_tc, k =4,  batch_size=75), model_build, optimizer, 50, 10, X_train, Y_train,  [alphas, lr] ,\n",
    "     [alpha_ranges, lr_ranges], verbose=100))\n",
    "    X = T.matrix()    \n",
    "    model = model_build(dataset_size=100)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "print np.mean(result)\n",
    "print np.std(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.08618924,  0.07302104]), array(0.00537222563090441)]\n",
      "0.845032090759\n",
      "[array([-0.11002089,  0.01758332]), array(0.005550579267265482)]\n",
      "0.845271989877\n",
      "[array([-0.08656351,  0.03525381]), array(0.005229430710384838)]\n",
      "0.845044330333\n",
      "[array([-0.14659154,  0.08547611]), array(0.005252349082338278)]\n",
      "0.845831519337\n",
      "[array([-0.08937141,  0.00927595]), array(0.0056384881157805575)]\n",
      "0.845004327496\n",
      "[array([-0.08553674,  0.06774782]), array(0.005466402939404961)]\n",
      "0.845007862766\n",
      "[array([-0.12797675,  0.05814624]), array(0.005692692163875986)]\n",
      "0.845512133854\n",
      "[array([-0.09096783,  0.05599656]), array(0.005646202917547017)]\n",
      "0.845048543537\n",
      "[array([-0.07663557,  0.00206454]), array(0.005492577281170933)]\n",
      "0.844863140164\n",
      "[array([-0.02383022,  0.01895683]), array(0.01000018614027096)]\n",
      "0.844238832863\n",
      "0.845085477098\n",
      "0.000394735187971\n"
     ]
    }
   ],
   "source": [
    "import theano.tensor as T\n",
    "X = T.matrix()\n",
    "result = []\n",
    "for b in bests:\n",
    "    print b.best_values\n",
    "    alphas.set_value(b.best_values[0])\n",
    "    lr.set_value(b.best_values[1])\n",
    "    training_procedure = cv_tc( model_build, optimizer, X_train, Y_train, validation_part=0.0, batch_size=100 )\n",
    "    \n",
    "    for i in xrange(10):\n",
    "        training_procedure.do_train()\n",
    "    \n",
    "    for m in training_procedure.models:\n",
    "        predict = m.predict_var(X)\n",
    "        predict = theano.function([X], predict)\n",
    "    \n",
    "        result.append(np.mean((predict(X_test)[:,0]-Y_test)**2))\n",
    "        print result[-1]\n",
    "    \"\"\"\n",
    "    bests.append( random_optimize(partial(cv_tc, k =4,  batch_size=75), model_build, optimizer, 50, 10, X_train, Y_train,  [alphas, lr] ,\n",
    "     [alpha_ranges, lr_ranges], verbose=100))\n",
    "    X = T.matrix()    \n",
    "    model = model_build(dataset_size=100)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "print np.mean(result)\n",
    "print np.std(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-115.117619924\n"
     ]
    }
   ],
   "source": [
    "best_values = []\n",
    "for b in bests:\n",
    "    history = []\n",
    "    for i in xrange(0, len(b.history)):\n",
    "        \n",
    "        best_value = max([h[1] for h in b.history[:i+1]])\n",
    "        \n",
    "        history.append(best_value)\n",
    "        best_values.append(history[-1])\n",
    "print np.mean(best_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEACAYAAABVmQgcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45655288d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(matrix.T)\n",
    "for i in bests:\n",
    "    i = i.best_values[0]\n",
    "    i = np.log10(np.exp(i)**2)\n",
    "    if i[0]>10 or i[1] >10:\n",
    "        continue\n",
    "    \n",
    "    plt.scatter(i[0]+np.random.randn(1)*0.1,i[1]+np.random.randn(1)*0.1, c='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.85777626,  3.48233214])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests[0].best_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'X2' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-96d5836345f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m greed_optimize(partial(cv_tc, k =4,  batch_size=10), model_build, optimizer, 1000, X, Y,  [alphas, lr] ,\n\u001b[0m\u001b[0;32m      2\u001b[0m     )\n",
      "\u001b[1;32m/home/legin/svn074/Bakhteev2017Hypergrad/code/pyfos/hyperoptimizers/greed_optimize.py\u001b[0m in \u001b[0;36mgreed_optimize\u001b[1;34m(trainig_criterion, model_constructor, param_optimizer, train_iteration_num, X_data, Y_data, hyperparams, lr, verbose)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mcosts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mgivens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mtrain_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'X2' referenced before assignment"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([array([  31.6227766 ,  316.22776602]), 0.001], array(-127.64285224474986)),\n",
       " ([array([ 10.        ,   3.16227766]), 0.01], array(-162.5087255392545)),\n",
       " ([array([ 31.6227766 ,   3.16227766]), 0.01], array(-2.7627426873481633e+42)),\n",
       " ([array([  10.,  100.]), 0.005], array(-124.3719052719263)),\n",
       " ([array([  3.16227766,  31.6227766 ]), 0.01], array(-1.2198974168241432e+41)),\n",
       " ([array([ 316.22776602,    1.        ]), 0.001], array(-122.78697142872564)),\n",
       " ([array([ 1.,  1.]), 0.01], array(-2.048288202990528e+45)),\n",
       " ([array([ 316.22776602,   10.        ]), 0.02], array(nan)),\n",
       " ([array([   1.,  100.]), 0.005], array(-127.03124347465777)),\n",
       " ([array([  3.16227766,  31.6227766 ]), 0.01], array(-3.879875247817619e+79))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+05   1.00000000e+00]\n",
      "[ 100.  100.]\n",
      "[ 100.  100.]\n",
      "[   1.  100.]\n",
      "[  1.  10.]\n"
     ]
    }
   ],
   "source": [
    "for i in bests:\n",
    "    print np.array(i.best_values[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPcAAAD7CAYAAAC2TgIoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVCjLLRXq/wHR0w+7QsHGpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f47241e5410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(matrix)\n",
    "for i in bests:\n",
    "    i = i.best_values[0]**2\n",
    "    i = np.log10(i)\n",
    "    \n",
    "    plt.scatter(i[0],i[1], c='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
