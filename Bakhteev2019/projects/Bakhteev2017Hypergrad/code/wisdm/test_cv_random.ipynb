{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../pyfos/')\n",
    "from pyfos.models.feedforward import build_feedforward\n",
    "from pyfos.generic.optimizer import gd_optimizer\n",
    "from pyfos.generic.regularizers import gaus_prior\n",
    "from functools import partial \n",
    "from pyfos.tc.simple import  simple_tc\n",
    "from pyfos.tc.cv import  cv_tc\n",
    "from pyfos.hyperoptimizers.random_search import random_optimize\n",
    "from pyfos.hyperoptimizers.no_optimize import no_optimize\n",
    "import theano\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12.   1.]\n",
      "[ 12.  12.  12. ...,   1.   1.   1.]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = np.load('../../../data/W_X_Tr.npy'), np.load('../../../data/W_X_Test.npy')\n",
    "Y_train, Y_test = np.load('../../../data/W_Y_Tr.npy'), np.load('../../../data/W_Y_Test.npy')\n",
    "\n",
    "param_num = X_train.shape[1] * 50 + 50 + 50  + 1\n",
    "\n",
    "lr = theano.shared(10**(-5))\n",
    "alphas = theano.shared(np.array([1.0, 1.0]))\n",
    "real_alphas = T.concatenate([T.repeat(alphas[0],  X_train.shape[1] * 50 + 50)   , T.repeat(alphas[1],  50 + 1) ])\n",
    "optimizer = partial(gd_optimizer, learning_rate=lr)\n",
    "model_build = partial(build_feedforward,  structure = [X_train.shape[1],50, 1],   init_sigmas=[0.001]*3, nonlinearity=lambda x:T.nnet.relu(x), log_alphas =real_alphas, bias=True)\n",
    "\n",
    "#for test\n",
    "alphas.set_value(np.array([12., 1.0]))\n",
    "print alphas.eval()\n",
    "print real_alphas.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3  3]\n"
     ]
    }
   ],
   "source": [
    "def choicer():\n",
    "    result = []\n",
    "    for i in xrange(param_num):\n",
    "        a1  = np.random.choice(range(-5, 5))\n",
    "        a2 =np.random.choice(range(-5, 5))\n",
    "        \n",
    "        \n",
    "    return np.array([a1,a2])\n",
    "print choicer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attemp\n",
      "hyperparams values: [-1. -4.]\n",
      "trial 0 iteration 0, internal loss=-1084046.59504\n",
      "score -1086257.31139 vs best -inf\n",
      "hyperparams values: [ 2.  3.]\n",
      "trial 1 iteration 0, internal loss=-1174105.59939\n",
      "score -1086249.70904 vs best -1086257.31139\n",
      "hyperparams values: [ 3. -5.]\n",
      "trial 2 iteration 0, internal loss=-1203584.68768\n",
      "score -1086286.35953 vs best -1086249.70904\n",
      "hyperparams values: [-2.  0.]\n",
      "trial 3 iteration 0, internal loss=-1054347.54312\n",
      "score -1086250.86451 vs best -1086249.70904\n",
      "hyperparams values: [-4. -1.]\n",
      "trial 4 iteration 0, internal loss=-994526.126803\n",
      "score -1086251.32047 vs best -1086249.70904\n",
      "hyperparams values: [ 0.  3.]\n",
      "trial 5 iteration 0, internal loss=-1114278.76798\n",
      "score -1086249.74808 vs best -1086249.70904\n",
      "hyperparams values: [ 0. -3.]\n",
      "trial 6 iteration 0, internal loss=-1113998.55618\n",
      "score -1086254.32144 vs best -1086249.70904\n",
      "hyperparams values: [-4.  3.]\n",
      "trial 7 iteration 0, internal loss=-994736.451789\n",
      "score -1086251.31328 vs best -1086249.70904\n",
      "hyperparams values: [-3.  1.]\n",
      "trial 8 iteration 0, internal loss=-1024480.06027\n",
      "score -1086251.30385 vs best -1086249.70904\n",
      "hyperparams values: [-1.  2.]\n",
      "trial 9 iteration 0, internal loss=-1084325.22535\n",
      "score -1086249.93432 vs best -1086249.70904\n",
      "hyperparams values: [-1. -1.]\n",
      "trial 10 iteration 0, internal loss=-1084186.02589\n",
      "score -1086250.53407 vs best -1086249.70904\n",
      "hyperparams values: [ 3.  1.]\n",
      "trial 11 iteration 0, internal loss=-1203911.78367\n",
      "score -1086249.58006 vs best -1086249.70904\n",
      "hyperparams values: [ 0.  4.]\n",
      "trial 12 iteration 0, internal loss=-1114347.40236\n",
      "score -1086249.68185 vs best -1086249.58006\n",
      "hyperparams values: [ 0. -1.]\n",
      "trial 13 iteration 0, internal loss=-1114086.48628\n",
      "score -1086250.39043 vs best -1086249.58006\n",
      "hyperparams values: [-2.  4.]\n",
      "trial 14 iteration 0, internal loss=-1054525.56141\n",
      "score -1086250.85002 vs best -1086249.58006\n",
      "hyperparams values: [-5.  0.]\n",
      "trial 15 iteration 0, internal loss=-964962.193003\n",
      "score -1086251.31845 vs best -1086249.58006\n",
      "hyperparams values: [-5. -1.]\n",
      "trial 16 iteration 0, internal loss=-964920.005627\n",
      "score -1086251.32872 vs best -1086249.58006\n",
      "hyperparams values: [-3.  4.]\n",
      "trial 17 iteration 0, internal loss=-1024652.3916\n",
      "score -1086251.3269 vs best -1086249.58006\n",
      "hyperparams values: [-5.  0.]\n",
      "trial 18 iteration 0, internal loss=-965003.222122\n",
      "score -1086251.31647 vs best -1086249.58006\n",
      "hyperparams values: [-4.  3.]\n",
      "trial 19 iteration 0, internal loss=-994729.878482\n",
      "score -1086251.31343 vs best -1086249.58006\n",
      "hyperparams values: [ 4. -1.]\n",
      "trial 20 iteration 0, internal loss=-1233663.45117\n",
      "score -1086250.3824 vs best -1086249.58006\n",
      "hyperparams values: [-1.  0.]\n",
      "trial 21 iteration 0, internal loss=-1084204.67451\n",
      "score -1086249.97064 vs best -1086249.58006\n",
      "hyperparams values: [-2.  2.]\n",
      "trial 22 iteration 0, internal loss=-1054424.23314\n",
      "score -1086250.83754 vs best -1086249.58006\n",
      "hyperparams values: [-4. -5.]\n",
      "trial 23 iteration 0, internal loss=-994317.466081\n",
      "score -1086397.22697 vs best -1086249.58006\n",
      "hyperparams values: [ 0.  4.]\n",
      "trial 24 iteration 0, internal loss=-1114358.81162\n",
      "score -1086249.63944 vs best -1086249.58006\n",
      "hyperparams values: [ 3.  4.]\n",
      "trial 25 iteration 0, internal loss=-1204048.3134\n",
      "score -1086249.54477 vs best -1086249.58006\n",
      "hyperparams values: [-1.  2.]\n",
      "trial 26 iteration 0, internal loss=-1084342.2573\n",
      "score -1086249.86428 vs best -1086249.54477\n",
      "hyperparams values: [-2. -1.]\n",
      "trial 27 iteration 0, internal loss=-1054279.65459\n",
      "score -1086251.17637 vs best -1086249.54477\n",
      "hyperparams values: [-3. -2.]\n",
      "trial 28 iteration 0, internal loss=-1024333.4157\n",
      "score -1086252.17911 vs best -1086249.54477\n",
      "hyperparams values: [-2. -1.]\n",
      "trial 29 iteration 0, internal loss=-1054310.86835\n",
      "score -1086251.18422 vs best -1086249.54477\n",
      "hyperparams values: [ 0. -2.]\n",
      "trial 30 iteration 0, internal loss=-1114037.48817\n",
      "score -1086252.47605 vs best -1086249.54477\n",
      "hyperparams values: [-2.  0.]\n",
      "trial 31 iteration 0, internal loss=-1054334.35002\n",
      "score -1086250.87069 vs best -1086249.54477\n",
      "hyperparams values: [-3. -1.]\n",
      "trial 32 iteration 0, internal loss=-1024403.41199\n",
      "score -1086251.33996 vs best -1086249.54477\n",
      "hyperparams values: [-4. -4.]\n",
      "trial 33 iteration 0, internal loss=-994381.767691\n",
      "score -1086272.75948 vs best -1086249.54477\n",
      "hyperparams values: [-5.  1.]\n",
      "trial 34 iteration 0, internal loss=-965033.89526\n",
      "score -1086251.31686 vs best -1086249.54477\n",
      "hyperparams values: [-1. -2.]\n",
      "trial 35 iteration 0, internal loss=-1084146.97566\n",
      "score -1086252.40811 vs best -1086249.54477\n",
      "hyperparams values: [ 1. -3.]\n",
      "trial 36 iteration 0, internal loss=-1143867.69643\n",
      "score -1086253.95577 vs best -1086249.54477\n",
      "hyperparams values: [-1. -2.]\n",
      "trial 37 iteration 0, internal loss=-1084112.73822\n",
      "score -1086252.4027 vs best -1086249.54477\n",
      "hyperparams values: [ 3.  4.]\n",
      "trial 38 iteration 0, internal loss=-1204038.27885\n",
      "score -1086249.58216 vs best -1086249.54477\n",
      "hyperparams values: [-1.  3.]\n",
      "trial 39 iteration 0, internal loss=-1084404.9075\n",
      "score -1086249.96218 vs best -1086249.54477\n",
      "hyperparams values: [ 4. -2.]\n",
      "trial 40 iteration 0, internal loss=-1233641.26061\n",
      "score -1086252.45462 vs best -1086249.54477\n",
      "hyperparams values: [-2.  4.]\n",
      "trial 41 iteration 0, internal loss=-1054544.7777\n",
      "score -1086250.82123 vs best -1086249.54477\n",
      "hyperparams values: [ 3.  3.]\n",
      "trial 42 iteration 0, internal loss=-1204001.98814\n",
      "score -1086249.6178 vs best -1086249.54477\n",
      "hyperparams values: [-3. -5.]\n",
      "trial 43 iteration 0, internal loss=-1024185.25168\n",
      "score -1086272.46322 vs best -1086249.54477\n",
      "hyperparams values: [ 1. -1.]\n",
      "trial 44 iteration 0, internal loss=-1143984.11752\n",
      "score -1086250.40753 vs best -1086249.54477\n",
      "hyperparams values: [ 1. -2.]\n",
      "trial 45 iteration 0, internal loss=-1143919.06464\n",
      "score -1086252.41947 vs best -1086249.54477\n",
      "hyperparams values: [-5. -4.]\n",
      "trial 46 iteration 0, internal loss=-964737.923802\n",
      "score -1086382.24976 vs best -1086249.54477\n",
      "hyperparams values: [ 2.  1.]\n",
      "trial 47 iteration 0, internal loss=-1173977.20752\n",
      "score -1086249.61092 vs best -1086249.54477\n",
      "hyperparams values: [-3. -2.]\n",
      "trial 48 iteration 0, internal loss=-1024360.61789\n",
      "score -1086252.10916 vs best -1086249.54477\n",
      "hyperparams values: [-2. -5.]\n",
      "trial 49 iteration 0, internal loss=-1054077.22427\n",
      "score -1086264.99078 vs best -1086249.54477\n",
      "-1086264.99078\n",
      "attemp\n",
      "hyperparams values: [ 0.  2.]\n",
      "trial 0 iteration 0, internal loss=-1114227.51618\n",
      "score -1086249.77743 vs best -inf\n",
      "hyperparams values: [ 3. -1.]\n",
      "trial 1 iteration 0, internal loss=-1203768.53175\n",
      "score -1086250.55358 vs best -1086249.77743\n",
      "hyperparams values: [-4. -3.]\n",
      "trial 2 iteration 0, internal loss=-994438.681584\n",
      "score -1086255.24262 vs best -1086249.77743\n",
      "hyperparams values: [-3. -1.]\n",
      "trial 3 iteration 0, internal loss=-1024398.64214\n",
      "score -1086251.56698 vs best -1086249.77743\n",
      "hyperparams values: [-5.  3.]\n",
      "trial 4 iteration 0, internal loss=-965113.111008\n",
      "score -1086251.5631 vs best -1086249.77743\n",
      "hyperparams values: [ 0.  3.]\n",
      "trial 5 iteration 0, internal loss=-1114290.70313\n",
      "score -1086249.91008 vs best -1086249.77743\n",
      "hyperparams values: [-1. -2.]\n",
      "trial 6 iteration 0, internal loss=-1084119.08011\n",
      "score -1086252.64789 vs best -1086249.77743\n",
      "hyperparams values: [-4. -3.]\n",
      "trial 7 iteration 0, internal loss=-994420.918071\n",
      "score -1086255.35801 vs best -1086249.77743\n",
      "hyperparams values: [-1.  0.]\n",
      "trial 8 iteration 0, internal loss=-1084222.13835\n",
      "score -1086250.15165 vs best -1086249.77743\n",
      "hyperparams values: [-3. -3.]\n",
      "trial 9 iteration 0, internal loss=-1024296.91469\n",
      "score -1086254.17136 vs best -1086249.77743\n",
      "hyperparams values: [-5. -4.]\n",
      "trial 10 iteration 0, internal loss=-964776.87715\n",
      "score -1086382.646 vs best -1086249.77743\n",
      "hyperparams values: [-1.  4.]\n",
      "trial 11 iteration 0, internal loss=-1084439.00301\n",
      "score -1086250.08499 vs best -1086249.77743\n",
      "hyperparams values: [-5.  4.]\n",
      "trial 12 iteration 0, internal loss=-965160.260287\n",
      "score -1086251.56693 vs best -1086249.77743\n",
      "hyperparams values: [ 0.  0.]\n",
      "trial 13 iteration 0, internal loss=-1114115.82566\n",
      "score -1086249.86513 vs best -1086249.77743\n",
      "hyperparams values: [ 1.  0.]\n",
      "trial 14 iteration 0, internal loss=-1144040.44639\n",
      "score -1086249.91914 vs best -1086249.77743\n",
      "hyperparams values: [-1.  3.]\n",
      "trial 15 iteration 0, internal loss=-1084419.14874\n",
      "score -1086250.01286 vs best -1086249.77743\n",
      "hyperparams values: [-3. -2.]\n",
      "trial 16 iteration 0, internal loss=-1024346.48685\n",
      "score -1086252.38429 vs best -1086249.77743\n",
      "hyperparams values: [ 0. -1.]\n",
      "trial 17 iteration 0, internal loss=-1114071.09077\n",
      "score -1086250.57331 vs best -1086249.77743\n",
      "hyperparams values: [ 2.  0.]\n",
      "trial 18 iteration 0, internal loss=-1173919.18547\n",
      "score -1086249.85069 vs best -1086249.77743\n",
      "hyperparams values: [-1.  4.]\n",
      "trial 19 iteration 0, internal loss=-1084446.71882\n",
      "score -1086250.10636 vs best -1086249.77743\n",
      "hyperparams values: [ 4.  0.]\n",
      "trial 20 iteration 0, internal loss=-1233755.10207\n",
      "score -1086249.8328 vs best -1086249.77743\n",
      "hyperparams values: [-2. -5.]\n",
      "trial 21 iteration 0, internal loss=-1054087.05067\n",
      "score -1086267.62084 vs best -1086249.77743\n",
      "hyperparams values: [-4.  4.]\n",
      "trial 22 iteration 0, internal loss=-994774.488287\n",
      "score -1086251.56686 vs best -1086249.77743\n",
      "hyperparams values: [ 3. -4.]\n",
      "trial 23 iteration 0, internal loss=-1203639.47039\n",
      "score -1086265.34499 vs best -1086249.77743\n",
      "hyperparams values: [ 3.  4.]\n",
      "trial 24 iteration 0, internal loss=-1204056.29642\n",
      "score -1086249.73845 vs best -1086249.77743\n",
      "hyperparams values: [-5. -5.]\n",
      "trial 25 iteration 0, internal loss=-964721.627654\n",
      "score -1086557.19899 vs best -1086249.73845\n",
      "hyperparams values: [-3. -5.]\n",
      "trial 26 iteration 0, internal loss=-1024174.38255\n",
      "score -1086273.33547 vs best -1086249.73845\n",
      "hyperparams values: [ 3.  3.]\n",
      "trial 27 iteration 0, internal loss=-1203989.64458\n",
      "score -1086249.78123 vs best -1086249.73845\n",
      "hyperparams values: [ 1. -3.]\n",
      "trial 28 iteration 0, internal loss=-1143897.90904\n",
      "score -1086254.16134 vs best -1086249.73845\n",
      "hyperparams values: [-4.  1.]\n",
      "trial 29 iteration 0, internal loss=-994610.289403\n",
      "score -1086251.56787 vs best -1086249.73845\n",
      "hyperparams values: [-2. -5.]\n",
      "trial 30 iteration 0, internal loss=-1054065.21394\n",
      "score -1086284.13202 vs best -1086249.73845\n",
      "hyperparams values: [ 3. -4.]\n",
      "trial 31 iteration 0, internal loss=-1203624.59049\n",
      "score -1086259.69206 vs best -1086249.73845\n",
      "hyperparams values: [-1.  4.]\n",
      "trial 32 iteration 0, internal loss=-1084427.05901\n",
      "score -1086250.11687 vs best -1086249.73845\n",
      "hyperparams values: [-3.  0.]\n",
      "trial 33 iteration 0, internal loss=-1024459.73102\n",
      "score -1086251.53961 vs best -1086249.73845\n",
      "hyperparams values: [ 0.  0.]\n",
      "trial 34 iteration 0, internal loss=-1114124.03514\n",
      "score -1086249.91388 vs best -1086249.73845\n",
      "hyperparams values: [-4.  0.]\n",
      "trial 35 iteration 0, internal loss=-994589.98848\n",
      "score -1086251.5659 vs best -1086249.73845\n",
      "hyperparams values: [-5.  3.]\n",
      "trial 36 iteration 0, internal loss=-965108.210003\n",
      "score -1086251.56571 vs best -1086249.73845\n",
      "hyperparams values: [-2.  2.]\n",
      "trial 37 iteration 0, internal loss=-1054444.68685\n",
      "score -1086251.04214 vs best -1086249.73845\n",
      "hyperparams values: [-4. -1.]\n",
      "trial 38 iteration 0, internal loss=-994538.650741\n",
      "score -1086251.57473 vs best -1086249.73845\n",
      "hyperparams values: [ 4.  0.]\n",
      "trial 39 iteration 0, internal loss=-1233755.81428\n",
      "score -1086249.7945 vs best -1086249.73845\n",
      "hyperparams values: [-5. -3.]\n",
      "trial 40 iteration 0, internal loss=-964809.03044\n",
      "score -1086261.94987 vs best -1086249.73845\n",
      "hyperparams values: [-4. -2.]\n",
      "trial 41 iteration 0, internal loss=-994484.576294\n",
      "score -1086251.83413 vs best -1086249.73845\n",
      "hyperparams values: [-5.  3.]\n",
      "trial 42 iteration 0, internal loss=-965098.632877\n",
      "score -1086251.56676 vs best -1086249.73845\n",
      "hyperparams values: [ 1. -3.]\n",
      "trial 43 iteration 0, internal loss=-1143879.01924\n",
      "score -1086254.21091 vs best -1086249.73845\n",
      "hyperparams values: [-4.  2.]\n",
      "trial 44 iteration 0, internal loss=-994683.401063\n",
      "score -1086251.56737 vs best -1086249.73845\n",
      "hyperparams values: [-3.  0.]\n",
      "trial 45 iteration 0, internal loss=-1024422.31006\n",
      "score -1086251.5822 vs best -1086249.73845\n",
      "hyperparams values: [-2. -1.]\n",
      "trial 46 iteration 0, internal loss=-1054289.7267\n",
      "score -1086251.54853 vs best -1086249.73845\n",
      "hyperparams values: [ 2.  3.]\n",
      "trial 47 iteration 0, internal loss=-1174067.64179\n",
      "score -1086249.9376 vs best -1086249.73845\n",
      "hyperparams values: [ 3.  0.]\n",
      "trial 48 iteration 0, internal loss=-1203805.32665\n",
      "score -1086249.87365 vs best -1086249.73845\n",
      "hyperparams values: [-2.  4.]\n",
      "trial 49 iteration 0, internal loss=-1054537.84297\n",
      "score -1086251.01449 vs best -1086249.73845\n",
      "-1086251.01449\n",
      "attemp\n",
      "hyperparams values: [-3. -2.]\n",
      "trial 0 iteration 0, internal loss=-1024345.36807\n",
      "score -1086252.1491 vs best -inf\n",
      "hyperparams values: [ 2. -4.]\n",
      "trial 1 iteration 0, internal loss=-1173716.68028\n",
      "score -1086255.29859 vs best -1086252.1491\n",
      "hyperparams values: [ 1.  1.]\n",
      "trial 2 iteration 0, internal loss=-1144070.47047\n",
      "score -1086249.7737 vs best -1086252.1491\n",
      "hyperparams values: [-1.  1.]\n",
      "trial 3 iteration 0, internal loss=-1084283.06898\n",
      "score -1086250.05745 vs best -1086249.7737\n",
      "hyperparams values: [ 2.  3.]\n",
      "trial 4 iteration 0, internal loss=-1174095.12002\n",
      "score -1086249.76649 vs best -1086249.7737\n",
      "hyperparams values: [-4.  0.]\n",
      "trial 5 iteration 0, internal loss=-994593.688556\n",
      "score -1086251.4086 vs best -1086249.76649\n",
      "hyperparams values: [ 2.  2.]\n",
      "trial 6 iteration 0, internal loss=-1174027.31733\n",
      "score -1086249.75301 vs best -1086249.76649\n",
      "hyperparams values: [ 0.  1.]\n",
      "trial 7 iteration 0, internal loss=-1114179.62472\n",
      "score -1086249.81622 vs best -1086249.75301\n",
      "hyperparams values: [-5.  1.]\n",
      "trial 8 iteration 0, internal loss=-965002.245781\n",
      "score -1086251.40833 vs best -1086249.75301\n",
      "hyperparams values: [ 2. -3.]\n",
      "trial 9 iteration 0, internal loss=-1173772.66444\n",
      "score -1086254.4221 vs best -1086249.75301\n",
      "hyperparams values: [ 3.  4.]\n",
      "trial 10 iteration 0, internal loss=-1204041.15475\n",
      "score -1086249.72476 vs best -1086249.75301\n",
      "hyperparams values: [ 4. -4.]\n",
      "trial 11 iteration 0, internal loss=-1233518.52066\n",
      "score -1086264.38501 vs best -1086249.72476\n",
      "hyperparams values: [ 2. -5.]\n",
      "trial 12 iteration 0, internal loss=-1173691.35627\n",
      "score -1086320.79406 vs best -1086249.72476\n",
      "hyperparams values: [-4. -3.]\n",
      "trial 13 iteration 0, internal loss=-994436.931813\n",
      "score -1086255.36929 vs best -1086249.72476\n",
      "hyperparams values: [-1. -4.]\n",
      "trial 14 iteration 0, internal loss=-1084025.45639\n",
      "score -1086255.40987 vs best -1086249.72476\n",
      "hyperparams values: [-2.  4.]\n",
      "trial 15 iteration 0, internal loss=-1054511.96359\n",
      "score -1086250.90671 vs best -1086249.72476\n",
      "hyperparams values: [-2. -1.]\n",
      "trial 16 iteration 0, internal loss=-1054283.84679\n",
      "score -1086251.30504 vs best -1086249.72476\n",
      "hyperparams values: [-4. -4.]\n",
      "trial 17 iteration 0, internal loss=-994387.791191\n",
      "score -1086274.37392 vs best -1086249.72476\n",
      "hyperparams values: [ 1. -2.]\n",
      "trial 18 iteration 0, internal loss=-1143932.04466\n",
      "score -1086252.58434 vs best -1086249.72476\n",
      "hyperparams values: [ 4. -1.]\n",
      "trial 19 iteration 0, internal loss=-1233686.54059\n",
      "score -1086250.58322 vs best -1086249.72476\n",
      "hyperparams values: [ 2.  0.]\n",
      "trial 20 iteration 0, internal loss=-1173932.60826\n",
      "score -1086249.91535 vs best -1086249.72476\n",
      "hyperparams values: [ 2.  1.]\n",
      "trial 21 iteration 0, internal loss=-1173982.54159\n",
      "score -1086249.79158 vs best -1086249.72476\n",
      "hyperparams values: [ 4. -5.]\n",
      "trial 22 iteration 0, internal loss=-1233475.55134\n",
      "score -1086371.60478 vs best -1086249.72476\n",
      "hyperparams values: [ 0.  4.]\n",
      "trial 23 iteration 0, internal loss=-1114339.72569\n",
      "score -1086249.84292 vs best -1086249.72476\n",
      "hyperparams values: [-3. -3.]\n",
      "trial 24 iteration 0, internal loss=-1024266.4438\n",
      "score -1086254.03446 vs best -1086249.72476\n",
      "hyperparams values: [ 4.  0.]\n",
      "trial 25 iteration 0, internal loss=-1233733.42436\n",
      "score -1086249.89709 vs best -1086249.72476\n",
      "hyperparams values: [-3. -5.]\n",
      "trial 26 iteration 0, internal loss=-1024199.14426\n",
      "score -1086273.27436 vs best -1086249.72476\n",
      "hyperparams values: [-1.  3.]\n",
      "trial 27 iteration 0, internal loss=-1084385.1093\n",
      "score -1086250.02378 vs best -1086249.72476\n",
      "hyperparams values: [-1.  1.]\n",
      "trial 28 iteration 0, internal loss=-1084280.9816\n",
      "score -1086250.13379 vs best -1086249.72476\n",
      "hyperparams values: [ 0.  3.]\n",
      "trial 29 iteration 0, internal loss=-1114313.30094\n",
      "score -1086249.81336 vs best -1086249.72476\n",
      "hyperparams values: [ 1.  2.]\n",
      "trial 30 iteration 0, internal loss=-1144122.7879\n",
      "score -1086249.78638 vs best -1086249.72476\n",
      "hyperparams values: [-1.  0.]\n",
      "trial 31 iteration 0, internal loss=-1084200.12838\n",
      "score -1086250.05727 vs best -1086249.72476\n",
      "hyperparams values: [-5.  4.]\n",
      "trial 32 iteration 0, internal loss=-965193.534211\n",
      "score -1086251.40965 vs best -1086249.72476\n",
      "hyperparams values: [-5. -2.]\n",
      "trial 33 iteration 0, internal loss=-964866.916653\n",
      "score -1086251.6328 vs best -1086249.72476\n",
      "hyperparams values: [-4.  1.]\n",
      "trial 34 iteration 0, internal loss=-994627.361795\n",
      "score -1086251.4071 vs best -1086249.72476\n",
      "hyperparams values: [-1.  4.]\n",
      "trial 35 iteration 0, internal loss=-1084432.28701\n",
      "score -1086249.99587 vs best -1086249.72476\n",
      "hyperparams values: [-2. -1.]\n",
      "trial 36 iteration 0, internal loss=-1054300.69027\n",
      "score -1086251.30904 vs best -1086249.72476\n",
      "hyperparams values: [ 0.  3.]\n",
      "trial 37 iteration 0, internal loss=-1114294.88301\n",
      "score -1086249.83378 vs best -1086249.72476\n",
      "hyperparams values: [-2.  2.]\n",
      "trial 38 iteration 0, internal loss=-1054436.18559\n",
      "score -1086250.89793 vs best -1086249.72476\n",
      "hyperparams values: [ 1.  0.]\n",
      "trial 39 iteration 0, internal loss=-1144054.64612\n",
      "score -1086249.86535 vs best -1086249.72476\n",
      "hyperparams values: [-4.  4.]\n",
      "trial 40 iteration 0, internal loss=-994776.218147\n",
      "score -1086251.40953 vs best -1086249.72476\n",
      "hyperparams values: [ 1.  2.]\n",
      "trial 41 iteration 0, internal loss=-1144124.4852\n",
      "score -1086249.81517 vs best -1086249.72476\n",
      "hyperparams values: [-2. -1.]\n",
      "trial 42 iteration 0, internal loss=-1054295.27076\n",
      "score -1086251.30354 vs best -1086249.72476\n",
      "hyperparams values: [ 4.  3.]\n",
      "trial 43 iteration 0, internal loss=-1233888.98211\n",
      "score -1086249.78058 vs best -1086249.72476\n",
      "hyperparams values: [-5.  1.]\n",
      "trial 44 iteration 0, internal loss=-965020.458328\n",
      "score -1086251.40781 vs best -1086249.72476\n",
      "hyperparams values: [ 3. -1.]\n",
      "trial 45 iteration 0, internal loss=-1203784.72678\n",
      "score -1086250.53264 vs best -1086249.72476\n",
      "hyperparams values: [ 2.  1.]\n",
      "trial 46 iteration 0, internal loss=-1173989.27258\n",
      "score -1086249.75979 vs best -1086249.72476\n",
      "hyperparams values: [ 4.  3.]\n",
      "trial 47 iteration 0, internal loss=-1233872.03017\n",
      "score -1086249.7904 vs best -1086249.72476\n",
      "hyperparams values: [-5. -1.]\n",
      "trial 48 iteration 0, internal loss=-964908.187207\n",
      "score -1086251.40901 vs best -1086249.72476\n",
      "hyperparams values: [-2.  3.]\n",
      "trial 49 iteration 0, internal loss=-1054482.0164\n",
      "score -1086250.93724 vs best -1086249.72476\n",
      "-1086250.93724\n",
      "attemp\n",
      "hyperparams values: [ 3. -3.]\n",
      "trial 0 iteration 0, internal loss=-1203676.13474\n",
      "score -1086254.33403 vs best -inf\n",
      "hyperparams values: [ 2.  0.]\n",
      "trial 1 iteration 0, internal loss=-1173927.067\n",
      "score -1086249.54394 vs best -1086254.33403\n",
      "hyperparams values: [ 4.  2.]\n",
      "trial 2 iteration 0, internal loss=-1233839.81712\n",
      "score -1086249.54784 vs best -1086249.54394\n",
      "hyperparams values: [-3.  3.]\n",
      "trial 3 iteration 0, internal loss=-1024614.38693\n",
      "score -1086251.27683 vs best -1086249.54394\n",
      "hyperparams values: [-2.  3.]\n",
      "trial 4 iteration 0, internal loss=-1054489.67524\n",
      "score -1086250.69085 vs best -1086249.54394\n",
      "hyperparams values: [-1.  1.]\n",
      "trial 5 iteration 0, internal loss=-1084262.94727\n",
      "score -1086249.8088 vs best -1086249.54394\n",
      "hyperparams values: [-1.  1.]\n",
      "trial 6 iteration 0, internal loss=-1084291.34679\n",
      "score -1086249.84252 vs best -1086249.54394\n",
      "hyperparams values: [-3. -2.]\n",
      "trial 7 iteration 0, internal loss=-1024337.95259\n",
      "score -1086251.93746 vs best -1086249.54394\n",
      "hyperparams values: [-5.  2.]\n",
      "trial 8 iteration 0, internal loss=-965071.246602\n",
      "score -1086251.22062 vs best -1086249.54394\n",
      "hyperparams values: [-1.  0.]\n",
      "trial 9 iteration 0, internal loss=-1084220.05793\n",
      "score -1086249.83637 vs best -1086249.54394\n",
      "hyperparams values: [-4.  3.]\n",
      "trial 10 iteration 0, internal loss=-994746.651342\n",
      "score -1086251.21657 vs best -1086249.54394\n",
      "hyperparams values: [-3.  0.]\n",
      "trial 11 iteration 0, internal loss=-1024440.27318\n",
      "score -1086251.18999 vs best -1086249.54394\n",
      "hyperparams values: [-2. -5.]\n",
      "trial 12 iteration 0, internal loss=-1054081.19297\n",
      "score -1086255.2709 vs best -1086249.54394\n",
      "hyperparams values: [-5.  2.]\n",
      "trial 13 iteration 0, internal loss=-965050.67122\n",
      "score -1086251.22081 vs best -1086249.54394\n",
      "hyperparams values: [-1.  3.]\n",
      "trial 14 iteration 0, internal loss=-1084395.13188\n",
      "score -1086249.77317 vs best -1086249.54394\n",
      "hyperparams values: [ 1.  3.]\n",
      "trial 15 iteration 0, internal loss=-1144179.63307\n",
      "score -1086249.52759 vs best -1086249.54394\n",
      "hyperparams values: [ 4.  4.]\n",
      "trial 16 iteration 0, internal loss=-1233926.67493\n",
      "score -1086249.49791 vs best -1086249.52759\n",
      "hyperparams values: [-1. -4.]\n",
      "trial 17 iteration 0, internal loss=-1084019.64301\n",
      "score -1086255.67017 vs best -1086249.49791\n",
      "hyperparams values: [-4. -5.]\n",
      "trial 18 iteration 0, internal loss=-994325.538268\n",
      "score -1086398.66835 vs best -1086249.49791\n",
      "hyperparams values: [-4. -2.]\n",
      "trial 19 iteration 0, internal loss=-994475.474541\n",
      "score -1086251.4489 vs best -1086249.49791\n",
      "hyperparams values: [-3.  4.]\n",
      "trial 20 iteration 0, internal loss=-1024666.61894\n",
      "score -1086251.17811 vs best -1086249.49791\n",
      "hyperparams values: [-1. -5.]\n",
      "trial 21 iteration 0, internal loss=-1083960.65969\n",
      "score -1086323.09229 vs best -1086249.49791\n",
      "hyperparams values: [-5. -2.]\n",
      "trial 22 iteration 0, internal loss=-964867.764425\n",
      "score -1086251.48873 vs best -1086249.49791\n",
      "hyperparams values: [-4. -5.]\n",
      "trial 23 iteration 0, internal loss=-994358.601464\n",
      "score -1086397.20143 vs best -1086249.49791\n",
      "hyperparams values: [ 0.  0.]\n",
      "trial 24 iteration 0, internal loss=-1114125.57743\n",
      "score -1086249.64485 vs best -1086249.49791\n",
      "hyperparams values: [-5.  2.]\n",
      "trial 25 iteration 0, internal loss=-965058.485164\n",
      "score -1086251.21905 vs best -1086249.49791\n",
      "hyperparams values: [ 3. -5.]\n",
      "trial 26 iteration 0, internal loss=-1203571.93981\n",
      "score -1086351.7293 vs best -1086249.49791\n",
      "hyperparams values: [ 1.  2.]\n",
      "trial 27 iteration 0, internal loss=-1144138.23066\n",
      "score -1086249.47305 vs best -1086249.49791\n",
      "hyperparams values: [ 0.  1.]\n",
      "trial 28 iteration 0, internal loss=-1114190.39725\n",
      "score -1086249.52989 vs best -1086249.47305\n",
      "hyperparams values: [ 3. -5.]\n",
      "trial 29 iteration 0, internal loss=-1203584.75703\n",
      "score -1086297.81417 vs best -1086249.47305\n",
      "hyperparams values: [ 2.  2.]\n",
      "trial 30 iteration 0, internal loss=-1174035.65276\n",
      "score -1086249.57964 vs best -1086249.47305\n",
      "hyperparams values: [-5.  2.]\n",
      "trial 31 iteration 0, internal loss=-965062.346853\n",
      "score -1086251.21689 vs best -1086249.47305\n",
      "hyperparams values: [ 0.  1.]\n",
      "trial 32 iteration 0, internal loss=-1114185.82425\n",
      "score -1086249.54892 vs best -1086249.47305\n",
      "hyperparams values: [-2. -5.]\n",
      "trial 33 iteration 0, internal loss=-1054073.59058\n",
      "score -1086262.69173 vs best -1086249.47305\n",
      "hyperparams values: [-5. -1.]\n",
      "trial 34 iteration 0, internal loss=-964891.822744\n",
      "score -1086251.22639 vs best -1086249.47305\n",
      "hyperparams values: [-4. -4.]\n",
      "trial 35 iteration 0, internal loss=-994383.511711\n",
      "score -1086273.55736 vs best -1086249.47305\n",
      "hyperparams values: [-1. -5.]\n",
      "trial 36 iteration 0, internal loss=-1083984.9914\n",
      "score -1086386.60662 vs best -1086249.47305\n",
      "hyperparams values: [-1. -1.]\n",
      "trial 37 iteration 0, internal loss=-1084166.712\n",
      "score -1086250.45201 vs best -1086249.47305\n",
      "hyperparams values: [-5. -5.]\n",
      "trial 38 iteration 0, internal loss=-964735.48585\n",
      "score -1086555.94991 vs best -1086249.47305\n",
      "hyperparams values: [ 1. -3.]\n",
      "trial 39 iteration 0, internal loss=-1143868.62589\n",
      "score -1086254.57736 vs best -1086249.47305\n",
      "hyperparams values: [-3. -5.]\n",
      "trial 40 iteration 0, internal loss=-1024191.96446\n",
      "score -1086273.20734 vs best -1086249.47305\n",
      "hyperparams values: [-4.  4.]\n",
      "trial 41 iteration 0, internal loss=-994766.763245\n",
      "score -1086251.21833 vs best -1086249.47305\n",
      "hyperparams values: [ 3.  1.]\n",
      "trial 42 iteration 0, internal loss=-1203902.18214\n",
      "score -1086249.53764 vs best -1086249.47305\n",
      "hyperparams values: [ 0.  3.]\n",
      "trial 43 iteration 0, internal loss=-1114286.43378\n",
      "score -1086249.56892 vs best -1086249.47305\n",
      "hyperparams values: [ 2. -3.]\n",
      "trial 44 iteration 0, internal loss=-1173794.59179\n",
      "score -1086253.74711 vs best -1086249.47305\n",
      "hyperparams values: [ 3.  2.]\n",
      "trial 45 iteration 0, internal loss=-1203931.02628\n",
      "score -1086249.58453 vs best -1086249.47305\n",
      "hyperparams values: [-1.  3.]\n",
      "trial 46 iteration 0, internal loss=-1084414.52362\n",
      "score -1086249.81737 vs best -1086249.47305\n",
      "hyperparams values: [-2.  0.]\n",
      "trial 47 iteration 0, internal loss=-1054319.36706\n",
      "score -1086250.90465 vs best -1086249.47305\n",
      "hyperparams values: [ 0. -5.]\n",
      "trial 48 iteration 0, internal loss=-1113871.44322\n",
      "score -1086271.07476 vs best -1086249.47305\n",
      "hyperparams values: [-3. -4.]\n",
      "trial 49 iteration 0, internal loss=-1024238.98096\n",
      "score -1086256.96579 vs best -1086249.47305\n",
      "-1086256.96579\n",
      "attemp\n",
      "hyperparams values: [ 2.  4.]\n",
      "trial 0 iteration 0, internal loss=-1174126.61697\n",
      "score -1086249.71362 vs best -inf\n",
      "hyperparams values: [-5.  0.]\n",
      "trial 1 iteration 0, internal loss=-964949.487222\n",
      "score -1086251.25308 vs best -1086249.71362\n",
      "hyperparams values: [-1.  4.]\n",
      "trial 2 iteration 0, internal loss=-1084421.53722\n",
      "score -1086249.92812 vs best -1086249.71362\n",
      "hyperparams values: [-5. -3.]\n",
      "trial 3 iteration 0, internal loss=-964806.589245\n",
      "score -1086261.87806 vs best -1086249.71362\n",
      "hyperparams values: [-3.  1.]\n",
      "trial 4 iteration 0, internal loss=-1024472.67789\n",
      "score -1086251.25258 vs best -1086249.71362\n",
      "hyperparams values: [-3.  0.]\n",
      "trial 5 iteration 0, internal loss=-1024439.03806\n",
      "score -1086251.25355 vs best -1086249.71362\n",
      "hyperparams values: [-3.  2.]\n",
      "trial 6 iteration 0, internal loss=-1024557.42851\n",
      "score -1086251.24893 vs best -1086249.71362\n",
      "hyperparams values: [ 3.  3.]\n",
      "trial 7 iteration 0, internal loss=-1203996.15542\n",
      "score -1086249.79988 vs best -1086249.71362\n",
      "hyperparams values: [-2.  4.]\n",
      "trial 8 iteration 0, internal loss=-1054544.33135\n",
      "score -1086250.82732 vs best -1086249.71362\n",
      "hyperparams values: [-3. -4.]\n",
      "trial 9 iteration 0, internal loss=-1024255.4931\n",
      "score -1086257.27321 vs best -1086249.71362\n",
      "hyperparams values: [ 2. -2.]\n",
      "trial 10 iteration 0, internal loss=-1173823.33413\n",
      "score -1086252.50421 vs best -1086249.71362\n",
      "hyperparams values: [ 3.  3.]\n",
      "trial 11 iteration 0, internal loss=-1203982.94968\n",
      "score -1086249.63532 vs best -1086249.71362\n",
      "hyperparams values: [-4.  4.]\n",
      "trial 12 iteration 0, internal loss=-994783.234919\n",
      "score -1086251.2548 vs best -1086249.63532\n",
      "hyperparams values: [ 2.  1.]\n",
      "trial 13 iteration 0, internal loss=-1173970.33377\n",
      "score -1086249.6984 vs best -1086249.63532\n",
      "hyperparams values: [ 3. -1.]\n",
      "trial 14 iteration 0, internal loss=-1203777.41244\n",
      "score -1086250.45363 vs best -1086249.63532\n",
      "hyperparams values: [ 2.  3.]\n",
      "trial 15 iteration 0, internal loss=-1174077.63053\n",
      "score -1086249.64135 vs best -1086249.63532\n",
      "hyperparams values: [ 1.  4.]\n",
      "trial 16 iteration 0, internal loss=-1144234.97353\n",
      "score -1086249.73532 vs best -1086249.63532\n",
      "hyperparams values: [ 0. -4.]\n",
      "trial 17 iteration 0, internal loss=-1113937.35943\n",
      "score -1086265.19751 vs best -1086249.63532\n",
      "hyperparams values: [ 0.  4.]\n",
      "trial 18 iteration 0, internal loss=-1114352.13654\n",
      "score -1086249.64953 vs best -1086249.63532\n",
      "hyperparams values: [ 4.  0.]\n",
      "trial 19 iteration 0, internal loss=-1233724.71604\n",
      "score -1086249.76957 vs best -1086249.63532\n",
      "hyperparams values: [ 4. -2.]\n",
      "trial 20 iteration 0, internal loss=-1233647.70063\n",
      "score -1086252.47289 vs best -1086249.63532\n",
      "hyperparams values: [-1. -2.]\n",
      "trial 21 iteration 0, internal loss=-1084138.29331\n",
      "score -1086252.48649 vs best -1086249.63532\n",
      "hyperparams values: [-3. -2.]\n",
      "trial 22 iteration 0, internal loss=-1024314.42196\n",
      "score -1086252.07521 vs best -1086249.63532\n",
      "hyperparams values: [ 4.  4.]\n",
      "trial 23 iteration 0, internal loss=-1233939.53081\n",
      "score -1086249.68515 vs best -1086249.63532\n",
      "hyperparams values: [ 1.  0.]\n",
      "trial 24 iteration 0, internal loss=-1144037.8934\n",
      "score -1086249.72424 vs best -1086249.63532\n",
      "hyperparams values: [-3. -4.]\n",
      "trial 25 iteration 0, internal loss=-1024242.7645\n",
      "score -1086256.0965 vs best -1086249.63532\n",
      "hyperparams values: [-5.  2.]\n",
      "trial 26 iteration 0, internal loss=-965093.599547\n",
      "score -1086251.25607 vs best -1086249.63532\n",
      "hyperparams values: [-5. -1.]\n",
      "trial 27 iteration 0, internal loss=-964918.076083\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d83b8f3afbee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'attemp'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     bests.append( random_optimize(tc, model_build, optimizer, 50, 10**4, X_train, Y_train,  [alphas] ,\n\u001b[1;32m----> 6\u001b[1;33m      [choicer], verbose=1000000))\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mbests\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/legin/svn074/Bakhteev2017Hypergrad/code/pyfos/hyperoptimizers/random_search.pyc\u001b[0m in \u001b[0;36mrandom_optimize\u001b[1;34m(trainig_criterion, model_constructor, param_optimizer, trial_num, train_iteration_num, X_data, Y_data, hyperparams, hyperparams_range, verbose)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iteration_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_procedure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[1;31m#print training_procedure.models[0].params.eval()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/legin/svn074/Bakhteev2017Hypergrad/code/pyfos/tc/cv.pyc\u001b[0m in \u001b[0;36mdo_train\u001b[1;34m(callback)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mcall_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcall_res\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcall_res\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bests = []\n",
    "for trial in range(5):\n",
    "    tc =  partial(cv_tc, k =4,  batch_size=25)\n",
    "    print 'attemp'\n",
    "    bests.append( random_optimize(tc, model_build, optimizer, 50, 10**4, X_train, Y_train,  [alphas] ,\n",
    "     [choicer], verbose=1000000))\n",
    "    print bests[-1].history[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import cPickle\n",
    "#with open('results_cv_rand.pckl','rb') as inp:\n",
    "#    bests = cPickle.load(inp)\n",
    "\n",
    "for b in bests:\n",
    "    history = []\n",
    "    for i in xrange(0, len(b.history)):\n",
    "        \n",
    "        best_value = max([h[1] for h in b.history[:i+1]])\n",
    "        \n",
    "        history.append(best_value)\n",
    "    plt.plot(history)\n",
    "#plt.ylim((-100, -80))\n",
    "plt.xlim((1,50))\n",
    "\n",
    "import cPickle\n",
    "with open('results_cv_rand.pckl','wb') as out:\n",
    "    cPickle.dump(bests, out)\n",
    "\n",
    "print bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([ 5.75646273,  1.15129255]), 0.01], array(-inf))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests[0].history[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.43914336962e-05\n",
      "0.000124289005293\n",
      "0.00129238139516\n",
      "0.000242562662603\n",
      "0.000779013165161\n",
      "0.0102724095201\n",
      "0.000206747922337\n",
      "0.000140740432021\n",
      "0.000132832862326\n",
      "8.03570899432e-06\n",
      "0.00749791590336\n",
      "6.75131708431e-05\n",
      "0.003461156779\n",
      "0.000129756949236\n",
      "0.000222773236192\n",
      "0.000242858305185\n",
      "7.31068395923e-06\n",
      "0.000446081971565\n",
      "2.10039527387e-05\n",
      "0.00498557348802\n",
      "0.000127393299536\n",
      "0.000344975987004\n",
      "0.00193295197259\n",
      "1.12403631093e-05\n",
      "0.00110372549492\n",
      "0.000169369711448\n",
      "8.88501579515e-05\n",
      "0.000371158334277\n",
      "5.25537631743e-05\n",
      "0.000169072496902\n",
      "6.99270861379e-05\n",
      "0.000118547148409\n",
      "0.00031077408314\n",
      "0.000360231067999\n",
      "0.00288808340749\n",
      "0.00124557541155\n",
      "0.0080222197081\n",
      "0.000376121747349\n",
      "0.000469794144926\n",
      "0.000297591329386\n",
      "0.00025797182711\n",
      "0.00567665490985\n",
      "2.50256902362e-05\n",
      "2.5725705823e-05\n",
      "3.9389787181e-05\n",
      "0.000166544706471\n",
      "0.000305865928779\n",
      "5.53252217421e-05\n",
      "0.000103489182896\n",
      "0.000183979775623\n",
      "0.000195866374435\n",
      "0.000208717300477\n",
      "2.41616115724e-05\n",
      "0.000922038736434\n",
      "0.000177551325219\n",
      "0.00052912656389\n",
      "0.000980365436934\n",
      "0.000392123433262\n",
      "0.000854405144585\n",
      "0.000125633289021\n",
      "0.0084750998913\n",
      "6.0865953532e-05\n",
      "2.47195201233e-05\n",
      "0.0219657832574\n",
      "4.51565572406e-05\n",
      "6.77217789663e-05\n",
      "0.00120027534512\n",
      "0.000341222200108\n",
      "8.28003001137e-05\n",
      "0.000549224347555\n",
      "0.00832597885439\n",
      "0.00187017232281\n",
      "0.00168977599448\n",
      "3.42599818764e-05\n",
      "0.000351331773181\n",
      "0.000863379008847\n",
      "3.773667364e-05\n",
      "2.51521629832e-05\n",
      "0.00479838694651\n",
      "1.07432667782e-05\n",
      "0.0130772213067\n",
      "0.000126185404682\n",
      "2.16785069426e-05\n",
      "0.000137885913645\n",
      "6.37559355887e-05\n",
      "2.74079693371e-05\n",
      "1.90408925581e-05\n",
      "0.000326320814701\n",
      "1.70845560038e-05\n",
      "0.0228499910101\n",
      "0.000176445411013\n",
      "8.39231508052e-05\n",
      "1.47892605331e-05\n",
      "0.000194927729238\n",
      "0.00125547543296\n",
      "0.00372906354441\n",
      "2.19683887134e-05\n",
      "0.00167026769434\n",
      "0.000105543204654\n",
      "0.000123607894831\n",
      "0.000605414293974\n",
      "6.01478433419e-05\n",
      "0.00115249607299\n",
      "8.23619941897e-05\n",
      "9.38518240975e-05\n",
      "0.00277399316189\n",
      "0.000153371759708\n",
      "4.5681880216e-06\n",
      "0.000123320105335\n",
      "1.0778295855e-05\n",
      "5.30587532614e-06\n",
      "0.00063274342395\n",
      "5.84731535167e-06\n",
      "0.000168065141339\n",
      "0.00146987632443\n",
      "0.00476572591548\n",
      "3.23905929221e-05\n",
      "0.0262438633737\n",
      "0.00212527316203\n",
      "0.00275525219534\n",
      "2.13297618402e-05\n",
      "0.00199988756079\n",
      "0.000260362863841\n",
      "1.12266231015e-05\n",
      "0.000271348438173\n",
      "0.0143831745657\n",
      "0.00112286194462\n",
      "8.9602670202e-05\n",
      "0.00100774960502\n",
      "0.000186375494929\n",
      "7.28526218113e-05\n",
      "1.78302943317e-06\n",
      "7.93760412038e-06\n",
      "0.00206809221017\n",
      "6.14242173641e-05\n",
      "0.0164493702629\n",
      "2.40674584057e-05\n",
      "0.000514272033379\n",
      "0.00232177317489\n",
      "0.000168234804593\n",
      "4.39629787099e-05\n",
      "0.00034700691144\n",
      "9.14152946724e-05\n",
      "0.000425076484167\n",
      "0.000565105756944\n",
      "0.000453078052759\n",
      "0.000168182570361\n",
      "0.0279508083721\n",
      "5.57923860772e-05\n",
      "9.11167474988e-05\n",
      "0.000151926977031\n",
      "7.32719263751e-05\n",
      "0.00382240558629\n",
      "0.00157591449238\n",
      "5.83441871446e-05\n",
      "0.000364801114324\n",
      "6.06025668379e-05\n",
      "0.00209037118424\n",
      "0.00099121695083\n",
      "0.000527575218507\n",
      "6.51765999646e-05\n",
      "9.81020084718e-05\n",
      "7.65670762083e-05\n",
      "0.000704570923519\n",
      "2.78463121498e-05\n",
      "0.00581071146549\n",
      "8.68342312852e-05\n",
      "0.00114972683496\n",
      "0.000479560476716\n",
      "2.05161972749e-05\n",
      "0.00292198089205\n",
      "2.3017978106e-05\n",
      "1.96447643846e-05\n",
      "0.000197040131181\n",
      "0.00047046512942\n",
      "0.000526950949515\n",
      "1.23250646758e-05\n",
      "0.000226050550827\n",
      "3.17766479925e-05\n",
      "2.54584886886e-05\n",
      "0.000110868001675\n",
      "8.96157166113e-05\n",
      "0.00058165419702\n",
      "4.95098482861e-05\n",
      "2.69233930305e-05\n",
      "0.00029423121532\n",
      "0.000111767179433\n",
      "0.000144472637014\n",
      "0.00117162619506\n",
      "0.000550564748599\n",
      "0.000707609378483\n",
      "2.81993504044e-05\n",
      "2.06246408371e-05\n",
      "8.28812904393e-05\n",
      "0.000126102329418\n",
      "0.000143104004125\n",
      "0.00347395424254\n",
      "1.04987176349e-05\n",
      "8.06925771789e-05\n",
      "0.000186139729788\n",
      "0.00150099774526\n",
      "0.00407938234164\n"
     ]
    }
   ],
   "source": [
    "import theano.tensor as T\n",
    "X = T.matrix()\n",
    "result = []\n",
    "models = []\n",
    "predicts = []\n",
    "\n",
    "for m in xrange(4):\n",
    "    models.append(model_build(dataset_size=100))\n",
    "    predict = models[m].predict_var(X)\n",
    "    predicts.append(theano.function([X], predict))\n",
    "for b in bests:\n",
    "    scores = [b.history[i][1] for i in xrange(len(b.history))]\n",
    "    best = np.argmax(scores)\n",
    "    \n",
    "    for m in xrange(4):\n",
    "        #print b.history[best][2][m]\n",
    "        models[m].params.set_value(b.history[best][2][m])\n",
    "        result.append(np.mean((predicts[m](X_test)[:,0]-Y_test)**2))\n",
    "        print result[-1]\n",
    "    \"\"\"\n",
    "    bests.append( random_optimize(partial(cv_tc, k =4,  batch_size=75), model_build, optimizer, 50, 10, X_train, Y_train,  [alphas, lr] ,\n",
    "     [alpha_ranges, lr_ranges], verbose=100))\n",
    "    X = T.matrix()    \n",
    "    model = model_build(dataset_size=100)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "print np.mean(result)\n",
    "print np.std(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-116.59428108\n"
     ]
    }
   ],
   "source": [
    "best_values = []\n",
    "for b in bests:\n",
    "    history = []\n",
    "    for i in xrange(0, len(b.history)):\n",
    "        \n",
    "        best_value = max([h[1] for h in b.history[:i+1]])\n",
    "        \n",
    "        history.append(best_value)\n",
    "        best_values.append(history[-1])\n",
    "print np.mean(best_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([array([  31.6227766 ,  316.22776602]), 0.001], array(-127.64285224474986)),\n",
       " ([array([ 10.        ,   3.16227766]), 0.01], array(-162.5087255392545)),\n",
       " ([array([ 31.6227766 ,   3.16227766]), 0.01], array(-2.7627426873481633e+42)),\n",
       " ([array([  10.,  100.]), 0.005], array(-124.3719052719263)),\n",
       " ([array([  3.16227766,  31.6227766 ]), 0.01], array(-1.2198974168241432e+41)),\n",
       " ([array([ 316.22776602,    1.        ]), 0.001], array(-122.78697142872564)),\n",
       " ([array([ 1.,  1.]), 0.01], array(-2.048288202990528e+45)),\n",
       " ([array([ 316.22776602,   10.        ]), 0.02], array(nan)),\n",
       " ([array([   1.,  100.]), 0.005], array(-127.03124347465777)),\n",
       " ([array([  3.16227766,  31.6227766 ]), 0.01], array(-3.879875247817619e+79))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.]\n",
      "[ 1.  1.]\n",
      "[ 10.   1.]\n",
      "[ 1.  1.]\n",
      "[ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "for i in bests:\n",
    "    print np.array(i.best_values[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEACAYAAABVmQgcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVfUaTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6dbaefdd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(matrix.T)\n",
    "for i in bests:\n",
    "    i = i.best_values[0]\n",
    "    i = np.log10(np.exp(2*i))\n",
    "    \n",
    "    plt.scatter(i[0]+np.random.randn(1)*0.1,i[1]+np.random.randn(1)*0.1, c='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model_build(dataset_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y = T.matrix(), T.vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = model.cost(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{add,no_inplace}.0\n"
     ]
    }
   ],
   "source": [
    "f = theano.function([X,Y], cost)\n",
    "print cost\n",
    "f2 = theano.function([X,Y], T.grad(cost, model.params))\n",
    "model.params.set_value([ 102.5926679 ,    0.23016751])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.02592668e+08,  -2.30167510e+05])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f(np.random.randn(100,2), np.random.randn(100))\n",
    "\n",
    "f2(np.random.randn(100,2), np.random.randn(100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
