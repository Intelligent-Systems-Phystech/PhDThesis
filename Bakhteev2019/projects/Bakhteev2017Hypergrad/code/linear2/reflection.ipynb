{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../pyfos/')\n",
    "from pyfos.models.feedforward import build_feedforward\n",
    "from pyfos.generic.optimizer import gd_optimizer\n",
    "from pyfos.generic.regularizers import gaus_prior\n",
    "from functools import partial \n",
    "from pyfos.tc.simple import  simple_tc\n",
    "from pyfos.tc.cv import  cv_tc\n",
    "from pyfos.hyperoptimizers.random_search import random_optimize\n",
    "from pyfos.hyperoptimizers.greed_optimize import greed_optimize\n",
    "import theano\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_size=20\n",
    "X_train = np.load('../../../data/linear2_x.npy').astype(theano.config.floatX)[:test_size]\n",
    "Y_train = np.load('../../../data/linear2_y.npy').astype(theano.config.floatX)[:test_size]\n",
    "\n",
    "X_test = np.load('../../../data/linear2_x.npy').astype(theano.config.floatX)[test_size:]\n",
    "Y_test = np.load('../../../data/linear2_y.npy').astype(theano.config.floatX)[test_size:]\n",
    "bias,var = np.load('../../../data/linear2_bias_var.npy')\n",
    "\n",
    "X = np.arange(-2, 2, 0.1)\n",
    "XX = np.vstack([ X,np.ones(X.shape[0]), X**2, X**3, X**4, X**5, X**6, X**7, X**8, X**9,  np.cos(X), np.sin(X)])\n",
    "XX = XX.T\n",
    "XX = (XX-bias)/var\n",
    "XX[:,1] =  np.ones(X.shape[0])\n",
    "XX = np.vstack([ XX.tolist(), X_train.tolist() , X_test.tolist()])\n",
    "\n",
    "XX=np.array(sorted(XX.tolist(), key=lambda x:x[0])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: YOU FORGOT TO REMOVE DEBUG FOR GREED OPTIMIZE\n"
     ]
    }
   ],
   "source": [
    "inits = [0.0]\n",
    "param_num = X_train.shape[1]\n",
    "alphas = theano.shared(np.random.randn(12).astype(theano.config.floatX))\n",
    "lr = theano.shared(np.array(7.5*10**(-3)).astype(theano.config.floatX))\n",
    "\n",
    "optimizer = partial(gd_optimizer, learning_rate=lr)\n",
    "\n",
    "model_build = partial(build_feedforward,  use_softmax=False,  structure = [X_train.shape[1], 1],   init_sigmas=inits, nonlinearity=lambda x:x, log_alphas =alphas, bias=False)\n",
    "tc = cv_tc(model_build, optimizer,X_train, Y_train, batch_size=test_size, k=1)\n",
    "tc.train_indices=[range(20)]\n",
    "tc.validation_indices=[range(20,40)]\n",
    "optimizer = partial(gd_optimizer, learning_rate=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = []\n",
    "\n",
    "for i in xrange(1000):\n",
    "    tc.do_train()\n",
    "    if i%50 == 0:\n",
    "        params.append(tc.models[0].params.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = np.array(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas.set_value(np.array([1]*12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: YOU FORGOT TO REMOVE DEBUG FOR GREED OPTIMIZE\n",
      "iteration 0, internal loss=-369.788721413, time=0.000293016433716\n",
      "iteration 100, internal loss=-361.205834779, time=0.00985383987427\n",
      "iteration 200, internal loss=-361.160671867, time=0.00940299034119\n",
      "iteration 300, internal loss=-361.135979053, time=0.00941300392151\n",
      "iteration 400, internal loss=-361.11933476, time=0.00945401191711\n",
      "iteration 500, internal loss=-361.107625707, time=0.0281059741974\n",
      "iteration 600, internal loss=-361.099116767, time=0.0135388374329\n",
      "iteration 700, internal loss=-361.092777322, time=0.0114130973816\n",
      "iteration 800, internal loss=-361.087967296, time=0.0105559825897\n",
      "iteration 900, internal loss=-361.084270409, time=0.00936484336853\n",
      "trial 0 [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])]\n",
      "iteration 0, internal loss=-369.788721413 hyperparam loss=-23.6687552753 time = 0.000367879867554\n",
      "iteration 100, internal loss=-361.265883057 hyperparam loss=-32.2274397371 time = 0.0230348110199\n",
      "iteration 200, internal loss=-361.121836562 hyperparam loss=-35.8131870342 time = 0.0224950313568\n",
      "iteration 300, internal loss=-360.79720008 hyperparam loss=-37.8613025934 time = 0.0239791870117\n",
      "iteration 400, internal loss=-359.954383278 hyperparam loss=-38.9818234746 time = 0.0351750850677\n",
      "iteration 500, internal loss=-356.516476904 hyperparam loss=-38.6326325101 time = 0.0255389213562\n",
      "iteration 600, internal loss=-354.06619957 hyperparam loss=-36.9304146752 time = 0.0286250114441\n",
      "iteration 700, internal loss=-353.634467141 hyperparam loss=-37.2544735491 time = 0.033872127533\n",
      "iteration 800, internal loss=-353.003645993 hyperparam loss=-36.6795912569 time = 0.0231139659882\n",
      "iteration 900, internal loss=-352.124856486 hyperparam loss=-35.3252013916 time = 0.0224030017853\n",
      "validation -24.0773667472\n",
      "trial 1 [array([ 1.60250111,  0.98271852,  1.13805912,  0.80964595,  0.23456187,\n",
      "       -2.57275294,  0.12938753, -2.52924873, -0.48468607, -0.36477124,\n",
      "        1.14401203,  1.5186971 ])]\n",
      "iteration 0, internal loss=-359.396845653 hyperparam loss=-23.6687552753 time = 0.00031304359436\n",
      "iteration 100, internal loss=-350.986865021 hyperparam loss=-29.5506109069 time = 0.0279030799866\n",
      "iteration 200, internal loss=-352.038827132 hyperparam loss=-30.5724762566 time = 0.0312929153442\n",
      "iteration 300, internal loss=-350.768316863 hyperparam loss=-30.0615817354 time = 0.0279579162598\n",
      "iteration 400, internal loss=-349.474475336 hyperparam loss=-28.9792726252 time = 0.0286459922791\n",
      "iteration 500, internal loss=-348.585432999 hyperparam loss=-28.0004031026 time = 0.0370149612427\n",
      "iteration 600, internal loss=-347.678991347 hyperparam loss=-26.9527967401 time = 0.0235929489136\n",
      "iteration 700, internal loss=-346.171682706 hyperparam loss=-26.4232459576 time = 0.0234639644623\n",
      "iteration 800, internal loss=-345.924495826 hyperparam loss=-26.253177496 time = 0.0223579406738\n",
      "iteration 900, internal loss=-345.821309865 hyperparam loss=-26.0733335927 time = 0.0483570098877\n",
      "validation -20.6342411886\n",
      "[ 1.73788607  0.98412719  1.13797319 -2.41377366 -0.44329098 -2.42932278\n",
      " -1.30897168 -2.28814239 -1.95712388  0.71667367  1.01100372  1.7011072 ]\n"
     ]
    }
   ],
   "source": [
    "greed_optimize(partial(cv_tc, k=1, batch_size=20)\n",
    "               , model_build, optimizer, 2, 20, 1000, np.vstack([X_train, X_test]), \n",
    "               np.hstack([Y_train, Y_test]), [alphas],lr=10**(-1), verbose=100\n",
    "              )\n",
    "print alphas.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
